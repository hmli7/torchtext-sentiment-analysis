{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] try bigram\n",
    " - [x] use pretraining embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(input_path, 'dev_text.txt'), 'r', encoding='utf-8') as f:\n",
    "#     dev_text = f.read().strip().split('\\n')\n",
    "\n",
    "# with open(os.path.join(input_path, 'heldout_text.txt'), 'r', encoding='utf-8') as f:\n",
    "#     heldout_text = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_label_path = os.path.join(input_path,'dev_label.txt')\n",
    "# with open(dev_label_path, 'r', encoding='utf-8') as f:\n",
    "#     dev_y = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data = pd.DataFrame({'text':dev_text, 'label':dev_y})\n",
    "\n",
    "# dev_data.to_csv(os.path.join(input_path, 'dev_data.tsv'), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.DataFrame({'text':heldout_text})\n",
    "# test_data.to_csv(os.path.join(input_path, 'test_data.tsv'), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "import baseline_lstm_model\n",
    "import config\n",
    "import util\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_packages = [paths, baseline_lstm_model, util, config]\n",
    "for package in reload_packages:\n",
    "    importlib.reload(package)\n",
    "# importlib.reload(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import random\n",
    "from torchtext.data import TabularDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_datafields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "dev_dataset = TabularDataset(\n",
    "               path=os.path.join(paths.input_path, 'dev_data.tsv'),\n",
    "               format='tsv',\n",
    "               skip_header=True,\n",
    "               fields=dev_datafields)\n",
    "\n",
    "test_datafields = [(\"text\", TEXT)]\n",
    "test_dataset = TabularDataset(\n",
    "           path=os.path.join(paths.input_path, 'test_data.tsv'),\n",
    "           format='csv',\n",
    "           skip_header=True,\n",
    "           fields=test_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = dev_dataset.split(split_ratio=0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [03:51, 3.73MB/s]                           \n",
      "100%|█████████▉| 399567/400000 [00:30<00:00, 21531.04it/s]"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_dataset, \n",
    "                 max_size = 40000, \n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_\n",
    "                )\n",
    "LABEL.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset), \n",
    "    batch_size = config.batch_size,\n",
    "    device = device,\n",
    "    sort = True,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True) #sort by length for padding\n",
    "\n",
    "test_iterator = data.Iterator(\n",
    "    test_dataset,\n",
    "    batch_size = config.batch_size, \n",
    "    device = device, \n",
    "    sort = False, \n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True, \n",
    "    repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'very', 'well', 'made', 'film']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 15700)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f0836fda1e0>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_lstm_model.BaselineLstm(vocab_size=len(TEXT.vocab), \n",
    "                                            embed_size=100, \n",
    "                                            hidden_size=128, \n",
    "                                            output_dim=1,\n",
    "                                            nlayers=3,\n",
    "                                            bidirectional=False,\n",
    "                                            lstm_dropout=0,\n",
    "                                            dropout=0.5,\n",
    "                                            pad_idx=TEXT.vocab.stoi[TEXT.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineLstm(\n",
       "  (embedding): Embedding(27331, 100, padding_idx=1)\n",
       "  (lstm): LSTM(100, 128, num_layers=3)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "# load embedding\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "# init unk token\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(100)\n",
    "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-03, weight_decay=1e-3)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_epoch, best_vali_loss, starting_epoch = 0, 400, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Epoch     0 \n",
      "Train Loss: 0.6922\tTrain Acc: 0.5047\tVal Loss: 0.6936\tVal Acc: 0.4879 \n",
      "Epoch time used:  5.585192918777466 s \n",
      "### Epoch     1 \n",
      "Train Loss: 0.6918\tTrain Acc: 0.5047\tVal Loss: 0.6936\tVal Acc: 0.4879 \n",
      "Epoch time used:  5.419354200363159 s \n",
      "### Epoch     2 \n",
      "Train Loss: 0.6909\tTrain Acc: 0.5069\tVal Loss: 0.6932\tVal Acc: 0.4879 \n",
      "Epoch time used:  5.4078826904296875 s \n",
      "### Epoch     3 \n",
      "Train Loss: 0.6895\tTrain Acc: 0.5147\tVal Loss: 0.6926\tVal Acc: 0.4912 \n",
      "Epoch time used:  5.408124685287476 s \n",
      "### Epoch     4 \n",
      "Train Loss: 0.6820\tTrain Acc: 0.6146\tVal Loss: 0.6876\tVal Acc: 0.5620 \n",
      "Epoch time used:  5.412967205047607 s \n",
      "### Epoch     5 \n",
      "Train Loss: 0.6771\tTrain Acc: 0.6165\tVal Loss: 0.6860\tVal Acc: 0.5587 \n",
      "Epoch time used:  5.226222991943359 s \n",
      "### Epoch     6 \n",
      "Train Loss: 0.6522\tTrain Acc: 0.6070\tVal Loss: 0.6699\tVal Acc: 0.5817 \n",
      "Epoch time used:  5.217249393463135 s \n",
      "### Epoch     7 \n",
      "Train Loss: 0.6363\tTrain Acc: 0.6219\tVal Loss: 0.6624\tVal Acc: 0.5954 \n",
      "Epoch time used:  5.426135540008545 s \n",
      "### Epoch     8 \n",
      "Train Loss: 0.5848\tTrain Acc: 0.7079\tVal Loss: 0.6453\tVal Acc: 0.6223 \n",
      "Epoch time used:  5.514202356338501 s \n",
      "### Epoch     9 \n",
      "Train Loss: 0.5342\tTrain Acc: 0.7386\tVal Loss: 0.6362\tVal Acc: 0.6425 \n",
      "Epoch time used:  5.426198959350586 s \n",
      "### Epoch    10 \n",
      "Train Loss: 0.5080\tTrain Acc: 0.7614\tVal Loss: 0.6313\tVal Acc: 0.6393 \n",
      "Epoch time used:  5.425390958786011 s \n",
      "### Epoch    11 \n",
      "Train Loss: 0.5076\tTrain Acc: 0.7370\tVal Loss: 0.6926\tVal Acc: 0.6168 \n",
      "Epoch time used:  5.381027460098267 s \n",
      "### Epoch    12 \n",
      "Train Loss: 0.4413\tTrain Acc: 0.8040\tVal Loss: 0.6654\tVal Acc: 0.6135 \n",
      "Epoch time used:  5.372707366943359 s \n",
      "### Epoch    13 \n",
      "Train Loss: 0.3916\tTrain Acc: 0.8224\tVal Loss: 0.7389\tVal Acc: 0.6414 \n",
      "Epoch time used:  5.391988754272461 s \n",
      "### Epoch    14 \n",
      "Train Loss: 0.3129\tTrain Acc: 0.9015\tVal Loss: 0.6142\tVal Acc: 0.6776 \n",
      "Epoch time used:  5.421807527542114 s \n",
      "### Epoch    15 \n",
      "Train Loss: 0.2818\tTrain Acc: 0.8873\tVal Loss: 0.6927\tVal Acc: 0.6727 \n",
      "Epoch time used:  5.385046482086182 s \n",
      "### Epoch    16 \n",
      "Train Loss: 0.3361\tTrain Acc: 0.8530\tVal Loss: 0.7654\tVal Acc: 0.6376 \n",
      "Epoch time used:  5.409461736679077 s \n",
      "### Epoch    17 \n",
      "Train Loss: 0.2836\tTrain Acc: 0.8942\tVal Loss: 0.6972\tVal Acc: 0.6612 \n",
      "Epoch time used:  5.3657097816467285 s \n",
      "### Epoch    18 \n",
      "Train Loss: 0.1556\tTrain Acc: 0.9439\tVal Loss: 0.7626\tVal Acc: 0.6776 \n",
      "Epoch time used:  5.36776876449585 s \n",
      "### Epoch    19 \n",
      "Train Loss: 0.2146\tTrain Acc: 0.9304\tVal Loss: 0.7012\tVal Acc: 0.6727 \n",
      "Epoch time used:  5.460144758224487 s \n",
      "### Epoch    20 \n",
      "Train Loss: 0.1405\tTrain Acc: 0.9659\tVal Loss: 0.7031\tVal Acc: 0.6815 \n",
      "Epoch time used:  5.373424530029297 s \n",
      "### Epoch    21 \n",
      "Train Loss: 0.1189\tTrain Acc: 0.9673\tVal Loss: 0.9072\tVal Acc: 0.6573 \n",
      "Epoch time used:  5.37949538230896 s \n",
      "### Epoch    22 \n",
      "Train Loss: 0.0796\tTrain Acc: 0.9773\tVal Loss: 0.8364\tVal Acc: 0.6826 \n",
      "Epoch time used:  5.371436834335327 s \n",
      "### Epoch    23 \n",
      "Train Loss: 0.1087\tTrain Acc: 0.9728\tVal Loss: 0.7222\tVal Acc: 0.6853 \n",
      "Epoch time used:  5.387443780899048 s \n",
      "### Epoch    24 \n",
      "Train Loss: 0.1469\tTrain Acc: 0.9638\tVal Loss: 0.7345\tVal Acc: 0.6502 \n",
      "Epoch time used:  5.376394033432007 s \n",
      "### Epoch    25 \n",
      "Train Loss: 0.0772\tTrain Acc: 0.9901\tVal Loss: 0.7161\tVal Acc: 0.6782 \n",
      "Epoch time used:  5.403357028961182 s \n",
      "### Epoch    26 \n",
      "Train Loss: 0.0559\tTrain Acc: 0.9929\tVal Loss: 0.7994\tVal Acc: 0.6700 \n",
      "Epoch time used:  5.381813049316406 s \n",
      "### Epoch    27 \n",
      "Train Loss: 0.0552\tTrain Acc: 0.9950\tVal Loss: 0.7947\tVal Acc: 0.6732 \n",
      "Epoch time used:  5.374530792236328 s \n",
      "### Epoch    28 \n",
      "Train Loss: 0.0615\tTrain Acc: 0.9893\tVal Loss: 0.9282\tVal Acc: 0.6700 \n",
      "Epoch time used:  5.379216194152832 s \n",
      "### Epoch    29 \n",
      "Train Loss: 0.0190\tTrain Acc: 0.9972\tVal Loss: 1.0151\tVal Acc: 0.6667 \n",
      "Epoch time used:  5.385440111160278 s \n",
      "### Epoch    30 \n",
      "Train Loss: 0.0308\tTrain Acc: 0.9957\tVal Loss: 0.9315\tVal Acc: 0.6782 \n",
      "Epoch time used:  5.393101215362549 s \n",
      "Summary: \n",
      "- Best Epoch: 14 | - Best Val Loss: 0.6142 \n"
     ]
    }
   ],
   "source": [
    "baseline_lstm_model.run(model, \n",
    "                        optimizer, \n",
    "                        criterion, \n",
    "                        train_iterator, \n",
    "                        valid_iterator, \n",
    "                        best_epoch=best_epoch, \n",
    "                        best_vali_loss=best_vali_loss, \n",
    "                        DEVICE=device, \n",
    "                        start_epoch=starting_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
