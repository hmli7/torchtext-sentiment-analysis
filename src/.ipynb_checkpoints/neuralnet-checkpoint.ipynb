{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - [ ] try bigram\n",
    " - [ ] use pretraining embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(input_path, 'dev_text.txt'), 'r', encoding='utf-8') as f:\n",
    "#     dev_text = f.read().strip().split('\\n')\n",
    "\n",
    "# with open(os.path.join(input_path, 'heldout_text.txt'), 'r', encoding='utf-8') as f:\n",
    "#     heldout_text = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_label_path = os.path.join(input_path,'dev_label.txt')\n",
    "# with open(dev_label_path, 'r', encoding='utf-8') as f:\n",
    "#     dev_y = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data = pd.DataFrame({'text':dev_text, 'label':dev_y})\n",
    "\n",
    "# dev_data.to_csv(os.path.join(input_path, 'dev_data.tsv'), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.DataFrame({'text':heldout_text})\n",
    "# test_data.to_csv(os.path.join(input_path, 'test_data.tsv'), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "import baseline_lstm_model\n",
    "import config\n",
    "import util\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_packages = [paths, baseline_lstm_model, util, config]\n",
    "for package in reload_packages:\n",
    "    importlib.reload(package)\n",
    "# importlib.reload(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "import random\n",
    "from torchtext.data import TabularDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_datafields = [(\"text\", TEXT), (\"label\", LABEL)]\n",
    "dev_dataset = TabularDataset(\n",
    "               path=os.path.join(paths.input_path, 'dev_data.tsv'),\n",
    "               format='tsv',\n",
    "               skip_header=True,\n",
    "               fields=dev_datafields)\n",
    "\n",
    "test_datafields = [(\"text\", TEXT)]\n",
    "test_dataset = TabularDataset(\n",
    "           path=os.path.join(paths.input_path, 'test_data.tsv'),\n",
    "           format='csv',\n",
    "           skip_header=True,\n",
    "           fields=test_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = dev_dataset.split(split_ratio=0.7, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [03:51, 3.73MB/s]                           \n",
      "100%|█████████▉| 399567/400000 [00:30<00:00, 21531.04it/s]"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_dataset, \n",
    "                 max_size = 40000, \n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_\n",
    "                )\n",
    "LABEL.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset), \n",
    "    batch_size = config.batch_size,\n",
    "    device = device,\n",
    "    sort = True,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True) #sort by length for padding\n",
    "\n",
    "test_iterator = data.Iterator(\n",
    "    test_dataset,\n",
    "    batch_size = config.batch_size, \n",
    "    device = device, \n",
    "    sort = False, \n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True, \n",
    "    repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'very', 'well', 'made', 'film']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 15700)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function _default_unk_index at 0x7f0836fda1e0>, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_lstm_model.BaselineLstm(vocab_size=len(TEXT.vocab), \n",
    "                                            embed_size=100, \n",
    "                                            hidden_size=128, \n",
    "                                            output_dim=1,\n",
    "                                            nlayers=3,\n",
    "                                            bidirectional=False,\n",
    "                                            lstm_dropout=0,\n",
    "                                            dropout=0.5,\n",
    "                                            pad_idx=TEXT.vocab.stoi[TEXT.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineLstm(\n",
       "  (embedding): Embedding(27331, 100, padding_idx=1)\n",
       "  (lstm): LSTM(100, 128, num_layers=3)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "# load embedding\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "# init unk token\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(100)\n",
    "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-03, weight_decay=1e-3)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_epoch, best_vali_loss, starting_epoch = 0, 400, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Epoch     0 \n"
     ]
    }
   ],
   "source": [
    "baseline_lstm_model.run(model, \n",
    "                        optimizer, \n",
    "                        criterion, \n",
    "                        train_iterator, \n",
    "                        valid_iterator, \n",
    "                        best_epoch=best_epoch, \n",
    "                        best_vali_loss=best_vali_loss, \n",
    "                        DEVICE=device, \n",
    "                        start_epoch=starting_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
