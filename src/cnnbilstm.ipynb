{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paths\n",
    "import data\n",
    "import ctc_crnn_model\n",
    "import phoneme_list\n",
    "import UtteranceDataset\n",
    "import config\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_packages = [paths, data, ctc_crnn_model, util, config]\n",
    "for package in reload_packages:\n",
    "    importlib.reload(package)\n",
    "# importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24724,) (24724,)\n",
      "Dataset Device: cuda\n",
      "(1106,) (1106,)\n",
      "Dataset Device: cuda\n"
     ]
    }
   ],
   "source": [
    "train_loader = data.get_loader(\"train\")\n",
    "val_loader = data.get_loader(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ctc_crnn_model.SpeechModel(phoneme_list.N_PHONEMES,num_rnn=4,hidden_size=512,nlayers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechModel(\n",
      "  (cnns): Sequential(\n",
      "    (0): Conv1d(40, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (rnns): ModuleList(\n",
      "    (0): LSTM(128, 512, bidirectional=True)\n",
      "    (1): LSTM(1024, 512, bidirectional=True)\n",
      "    (2): LSTM(1024, 512, bidirectional=True)\n",
      "    (3): LSTM(1024, 512, bidirectional=True)\n",
      "  )\n",
      "  (scoring): Linear(in_features=1024, out_features=47, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == torch.nn.Conv1d or type(m) == torch.nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechModel(\n",
       "  (cnns): Sequential(\n",
       "    (0): Conv1d(40, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (rnns): ModuleList(\n",
       "    (0): LSTM(128, 512, bidirectional=True)\n",
       "    (1): LSTM(1024, 512, bidirectional=True)\n",
       "    (2): LSTM(1024, 512, bidirectional=True)\n",
       "    (3): LSTM(1024, 512, bidirectional=True)\n",
       "  )\n",
       "  (scoring): Linear(in_features=1024, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize cnn layers\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize rnn layers\n",
    "ctc_crnn_model.init_weights(model, weight_init=torch.nn.init.orthogonal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, nesterov=True)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3*0.5, weight_decay=5e-4)\n",
    "\n",
    "best_epoch, best_vali_loss, starting_epoch = 0, 400, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../outputs/4bilstm_adam_10.pth.tar'\n",
      "=> loaded checkpoint '../outputs/4bilstm_adam_10.pth.tar' (epoch 10)\n"
     ]
    }
   ],
   "source": [
    "# proceeding from old models\n",
    "model_path = os.path.join(paths.output_path, '4bilstm_adam_10.pth.tar')\n",
    "print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "checkpoint = torch.load(model_path)\n",
    "starting_epoch = checkpoint['epoch']+1\n",
    "# best_vali_acc = checkpoint['best_vali_acc']\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "model.load_state_dict(model_state_dict)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_label_state_dict'])\n",
    "best_vali_loss = checkpoint['best_vali_loss']\n",
    "best_epoch = checkpoint['best_epoch']\n",
    "print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "      .format(model_path, checkpoint['epoch']))\n",
    "# del checkpoint, model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 25.023090839385986)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch, best_vali_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.000125\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] = lr=0.00025*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Starting training with scheduler.\n",
      "### Epoch    11 \n",
      "Epoch: 11\tBatch: 50\tAvg-Loss: 2.8695 \n",
      "Epoch: 11\tBatch: 100\tAvg-Loss: 2.6571 \n",
      "Epoch: 11\tBatch: 150\tAvg-Loss: 2.4437 \n",
      "Epoch: 11\tBatch: 200\tAvg-Loss: 2.3853 \n",
      "Epoch: 11\tBatch: 250\tAvg-Loss: 2.3259 \n",
      "Epoch: 11\tBatch: 300\tAvg-Loss: 2.3572 \n",
      "Epoch: 11\tBatch: 350\tAvg-Loss: 2.2635 \n",
      "Train Loss: 1.8298\tVal Loss: 27.9660\t \n",
      "start eval\n",
      "vali_distance: 6.4715\t \n",
      "Epoch time used:  573.6263682842255 s \n",
      "### Epoch    12 \n",
      "Epoch: 12\tBatch: 50\tAvg-Loss: 1.8416 \n",
      "Epoch: 12\tBatch: 100\tAvg-Loss: 1.8242 \n",
      "Epoch: 12\tBatch: 150\tAvg-Loss: 1.8021 \n",
      "Epoch: 12\tBatch: 200\tAvg-Loss: 1.8916 \n",
      "Epoch: 12\tBatch: 250\tAvg-Loss: 1.9154 \n",
      "Epoch: 12\tBatch: 300\tAvg-Loss: 1.8032 \n",
      "Epoch: 12\tBatch: 350\tAvg-Loss: 1.8440 \n",
      "Train Loss: 1.4536\tVal Loss: 29.0074\t \n",
      "start eval\n",
      "vali_distance: 6.5503\t \n",
      "Epoch     1: reducing learning rate of group 0 to 6.2500e-05.\n",
      "Epoch time used:  573.7871663570404 s \n",
      "### Epoch    13 \n",
      "Epoch: 13\tBatch: 50\tAvg-Loss: 1.4240 \n",
      "Epoch: 13\tBatch: 100\tAvg-Loss: 1.4476 \n",
      "Epoch: 13\tBatch: 150\tAvg-Loss: 1.4824 \n",
      "Epoch: 13\tBatch: 200\tAvg-Loss: 1.5188 \n",
      "Epoch: 13\tBatch: 250\tAvg-Loss: 1.4224 \n",
      "Epoch: 13\tBatch: 300\tAvg-Loss: 1.4894 \n",
      "Epoch: 13\tBatch: 350\tAvg-Loss: 1.3895 \n",
      "Train Loss: 1.2372\tVal Loss: 29.6475\t \n",
      "start eval\n",
      "vali_distance: 6.4748\t \n",
      "Epoch     2: reducing learning rate of group 0 to 3.1250e-05.\n",
      "Epoch time used:  574.984071969986 s \n",
      "### Epoch    14 \n",
      "Epoch: 14\tBatch: 50\tAvg-Loss: 1.2973 \n",
      "Epoch: 14\tBatch: 100\tAvg-Loss: 1.1904 \n",
      "Epoch: 14\tBatch: 150\tAvg-Loss: 1.2619 \n",
      "Epoch: 14\tBatch: 200\tAvg-Loss: 1.2638 \n",
      "Epoch: 14\tBatch: 250\tAvg-Loss: 1.2904 \n",
      "Epoch: 14\tBatch: 300\tAvg-Loss: 1.2929 \n",
      "Epoch: 14\tBatch: 350\tAvg-Loss: 1.2596 \n",
      "Train Loss: 1.1254\tVal Loss: 30.0114\t \n",
      "start eval\n",
      "vali_distance: 6.5146\t \n",
      "Epoch     3: reducing learning rate of group 0 to 1.5625e-05.\n",
      "Epoch time used:  574.052294254303 s \n",
      "### Epoch    15 \n",
      "Epoch: 15\tBatch: 50\tAvg-Loss: 1.2023 \n",
      "Epoch: 15\tBatch: 100\tAvg-Loss: 1.1703 \n",
      "Epoch: 15\tBatch: 150\tAvg-Loss: 1.1278 \n",
      "Epoch: 15\tBatch: 200\tAvg-Loss: 1.2039 \n",
      "Epoch: 15\tBatch: 250\tAvg-Loss: 1.1480 \n",
      "Epoch: 15\tBatch: 300\tAvg-Loss: 1.1044 \n",
      "Epoch: 15\tBatch: 350\tAvg-Loss: 1.1339 \n",
      "Train Loss: 1.0759\tVal Loss: 30.1871\t \n",
      "start eval\n",
      "vali_distance: 6.5041\t \n",
      "Epoch     4: reducing learning rate of group 0 to 7.8125e-06.\n",
      "Epoch time used:  573.6263499259949 s \n",
      "### Epoch    16 \n",
      "Epoch: 16\tBatch: 50\tAvg-Loss: 1.0520 \n",
      "Epoch: 16\tBatch: 100\tAvg-Loss: 1.1397 \n",
      "Epoch: 16\tBatch: 150\tAvg-Loss: 1.1279 \n",
      "Epoch: 16\tBatch: 200\tAvg-Loss: 1.0755 \n",
      "Epoch: 16\tBatch: 250\tAvg-Loss: 1.1012 \n",
      "Epoch: 16\tBatch: 300\tAvg-Loss: 1.1212 \n",
      "Epoch: 16\tBatch: 350\tAvg-Loss: 1.0898 \n",
      "Train Loss: 1.0408\tVal Loss: 30.3204\t \n",
      "start eval\n",
      "vali_distance: 6.5292\t \n",
      "Epoch     5: reducing learning rate of group 0 to 3.9063e-06.\n",
      "Epoch time used:  574.4807069301605 s \n",
      "### Epoch    17 \n",
      "Epoch: 17\tBatch: 50\tAvg-Loss: 1.1066 \n",
      "Epoch: 17\tBatch: 100\tAvg-Loss: 1.0447 \n",
      "Epoch: 17\tBatch: 150\tAvg-Loss: 1.1037 \n",
      "Epoch: 17\tBatch: 200\tAvg-Loss: 1.0726 \n",
      "Epoch: 17\tBatch: 250\tAvg-Loss: 1.0500 \n",
      "Epoch: 17\tBatch: 300\tAvg-Loss: 1.0763 \n",
      "Epoch: 17\tBatch: 350\tAvg-Loss: 1.0915 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-4cba8b316495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                              best_epoch, best_vali_loss, starting_epoch)\n\u001b[0m",
      "\u001b[0;32m~/deeplearning/hw3/deep_learning_ctc/codes/ctc_crnn_model.py\u001b[0m in \u001b[0;36mrun_with_scheduler\u001b[0;34m(model, optimizer, scheduler_patience, scheduler_factor, train_dataloader, valid_dataloader, best_epoch, best_vali_loss, start_epoch)\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mprint_file_and_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Loss: {:.4f}\\tVal Loss: {:.4f}\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/hw3/deep_learning_ctc/codes/ctc_crnn_model.py\u001b[0m in \u001b[0;36mtest_validation\u001b[0;34m(model, valid_dataloader)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mctc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTCCriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mphoneme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mtarget_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoneme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/hw3/deep_learning_ctc/codes/ctc_crnn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq_batch)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0moutput_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lens_rnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unpacked output (padded)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mscores_flatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 182\u001b[0;31m                            self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ctc_model.run(model, optimizer, train_loader, val_loader, best_epoch, best_vali_loss, starting_epoch)\n",
    "ctc_crnn_model.run_with_scheduler(model,\n",
    "                             optimizer, 0, 0.5,\n",
    "                             train_loader, val_loader, \n",
    "                             best_epoch, best_vali_loss, starting_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.wrap_up_experiment(os.path.join(paths.output_path, 'metrics.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctc_model.run_eval(model_2, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Device: cuda\n"
     ]
    }
   ],
   "source": [
    "test_loader = data.get_loader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../outputs/4bilstm_adam_11.pth.tar'\n",
      "=> loaded checkpoint '../outputs/4bilstm_adam_11.pth.tar' (epoch 11)\n",
      "start prediction\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "=> loading checkpoint '../outputs/4bilstm_adam_11_2.pth.tar'\n",
      "=> loaded checkpoint '../outputs/4bilstm_adam_11_2.pth.tar' (epoch 11)\n",
      "start prediction\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "=> loading checkpoint '../outputs/4bilstm_adam_11_3.pth.tar'\n",
      "=> loaded checkpoint '../outputs/4bilstm_adam_11_3.pth.tar' (epoch 11)\n",
      "start prediction\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "for epoch in [11, '11_2', '11_3']:\n",
    "    # checkpoint = torch.load(\"checkpoint.pt\")\n",
    "    model_prediction = ctc_crnn_model.SpeechModel(phoneme_list.N_PHONEMES,num_rnn=4,hidden_size=512,nlayers=1)\n",
    "\n",
    "    # proceeding from old models\n",
    "    model_path = os.path.join(paths.output_path, '4bilstm_adam_'+str(epoch)+'.pth.tar')\n",
    "    print(\"=> loading checkpoint '{}'\".format(model_path))\n",
    "    checkpoint = torch.load(model_path)\n",
    "    starting_epoch = checkpoint['epoch']\n",
    "    # best_vali_acc = checkpoint['best_vali_acc']\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "    model_prediction.load_state_dict(model_state_dict)\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    best_vali_loss = checkpoint['best_vali_loss']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "          .format(model_path, checkpoint['epoch']))\n",
    "    # del checkpoint, model_state_dict\n",
    "\n",
    "    best_epoch\n",
    "\n",
    "    model_prediction.cuda()\n",
    "\n",
    "    encoded_prediction = ctc_crnn_model.predict(model_prediction, test_loader)\n",
    "\n",
    "    import pandas as pd\n",
    "    varification_results_df = pd.DataFrame({'Id':np.arange(len(test_loader)), 'predicted':np.array(encoded_prediction).flatten()})\n",
    "\n",
    "    varification_results_df.to_csv(os.path.join('..','outputs', 'verification_submission_'+str(epoch)+'.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ctcdecode.CTCBeamDecoder at 0x7fe9bf4c1240>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctc_crnn_model.ER().decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(3/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
